{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of artificial neural networks must be initialized to small random numbers.\n",
    "\n",
    "This is because this is an expectation of the stochastic optimization algorithm used to train the model, called stochastic gradient descent.\n",
    "\n",
    "To understand this approach to problem solving, you must first understand the role of nondeterministic and randomized algorithms as well as the need for stochastic optimization algorithms to harness randomness in their search process.\n",
    "\n",
    "In this post, you will discover the full background as to why neural network weights must be randomly initialized."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Initialization Methods\n",
    "Traditionally, the weights of a neural network were set to small random numbers.\n",
    "\n",
    "The initialization of the weights of neural networks is a whole field of study as the careful initialization of the network can speed up the learning process.\n",
    "\n",
    "Modern deep learning libraries, such as Keras, offer a host of network initialization methods, all are variations of initializing the weights with small random numbers.\n",
    "\n",
    "For example, the current methods are available in Keras at the time of writing for all network types:\n",
    "\n",
    "Zeros: Initializer that generates tensors initialized to 0.\n",
    "    \n",
    "keras.initializers.Zeros()    \n",
    "    \n",
    "    \n",
    "   \n",
    "Ones: Initializer that generates tensors initialized to 1.\n",
    "keras.initializers.Ones()\n",
    "\n",
    "\n",
    "Constant: Initializer that generates tensors initialized to a constant value.\n",
    "keras.initializers.Constant(value=0)\n",
    "\n",
    "\n",
    "RandomNormal: Initializer that generates tensors with a normal distribution.\n",
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "\n",
    "\n",
    "\n",
    "RandomUniform: Initializer that generates tensors with a uniform distribution.\n",
    "keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "\n",
    "\n",
    "TruncatedNormal: Initializer that generates a truncated normal distribution.\n",
    "keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "\n",
    "\n",
    "\n",
    "VarianceScaling: Initializer capable of adapting its scale to the shape of weights.\n",
    "keras.initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
    "\n",
    "\n",
    "Orthogonal: Initializer that generates a random orthogonal matrix.\n",
    "keras.initializers.Orthogonal(gain=1.0, seed=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Identity: Initializer that generates the identity matrix.\n",
    "keras.initializers.Identity(gain=1.0)\n",
    "\n",
    "\n",
    "\n",
    "lecun_uniform: LeCun uniform initializer.\n",
    "keras.initializers.lecun_uniform(seed=None)\n",
    "\n",
    "\n",
    "\n",
    "glorot_normal: Glorot normal initializer, also called Xavier normal initializer.\n",
    "keras.initializers.glorot_normal(seed=None)\n",
    "\n",
    "\n",
    "glorot_uniform: Glorot uniform initializer, also called Xavier uniform initializer.\n",
    "keras.initializers.glorot_uniform(seed=None)\n",
    "\n",
    "\n",
    "he_normal: He normal initializer.\n",
    "keras.initializers.he_normal(seed=None)\n",
    "\n",
    "\n",
    "lecun_normal: LeCun normal initializer.\n",
    "keras.initializers.lecun_normal(seed=None)\n",
    "\n",
    "\n",
    "he_uniform: He uniform variance scaling initializer.\n",
    "keras.initializers.he_uniform(seed=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using custom initializers\n",
    "If passing a custom callable, then it must take the argument shape (shape of the variable to initialize) and dtype (dtype of generated values):\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def my_init(shape, dtype=None):\n",
    "    return K.random_normal(shape, dtype=dtype)\n",
    "\n",
    "model.add(Dense(64, kernel_initializer=my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coutesy Jason Brownlee and Keras Documentation (https://keras.io/initializers/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
